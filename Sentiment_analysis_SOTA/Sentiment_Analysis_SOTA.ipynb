{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_SOTA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqST-Ny3WC97"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import re\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUhtvQK-5JrH"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRrpuBHBWv69"
      },
      "source": [
        "# Convert csv files to input and labels lists\n",
        "def read_csv(filename = 'data/emojify_data.csv'):\n",
        "    text = []\n",
        "    label = []\n",
        "\n",
        "    with open (filename) as csvDataFile:\n",
        "        csvReader = csv.reader(csvDataFile)\n",
        "        next(csvReader, None)\n",
        "        for row in csvReader:\n",
        "            text.append(row[1])\n",
        "            label.append(re.search(\"[1-5]\",row[2]).group(0))\n",
        "\n",
        "    X = list(text)\n",
        "    Y = np.array(label, dtype=int)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9comnebvU5Rh"
      },
      "source": [
        "# returning input and output lists\n",
        "X_train, Y_train = read_csv('sentiment_dataset_train.csv')\n",
        "X_eval, Y_eval = read_csv('sentiment_dataset_dev.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbtGESugXrqY",
        "outputId": "20568460-df5c-442f-f1eb-e2aba7dbe2e4"
      },
      "source": [
        "# sample review with rating\n",
        "print(X_train[0], \"Rating :\",Y_train[0])\n",
        "len(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arrived about 10pm and check in was painless.   The only downside to this hotel is if you are looking for a city centre location. If you don't mind some walking and want to be out of the noise of the city then this place is ideal.   Hotel has a bar and restaurant, decent size gym and roof terrace with sun loungers.   The rooms are a good size, especially when traveling with a large teenager. Good sized lounge with double sofa bed, kitchen area and dining table. Main bedroom is a good size with double wardrobes and safe. Shower room is well sized with plenty of towels, good supply of toiletries, and hairdryer.   Fridge comes stocked with bottles of water to get you started and you can get more at the hotel bar  A 5 minute walk takes you to Marina metro station and your access toâ€¦ Rating : 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "789"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DrvA6pfbeRl"
      },
      "source": [
        "# Convert label to one-hot tensors\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88DXupeTctrv"
      },
      "source": [
        "# Convert label to one-hot tensors\n",
        "Y_oh_train = convert_to_one_hot(Y_train, C = 6)\n",
        "Y_oh_eval = convert_to_one_hot(Y_eval, C =6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNvhro1ycz_T",
        "outputId": "25b7ba77-4540-4e0c-94a0-89c99b767a69"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "# preprocess each review to remove hyperlinks, duplicate letters (i.e, sooo), punctuation marks\n",
        "def pre_process(tweet):\n",
        "  tweet = tweet.strip().lower()\n",
        "  tweet = re.sub(r'http[s]?://\\S+','',tweet)  #/https?\\:(\\\\\\\\|\\/\\/)(www.)?/,'' re.sub('http[s]?://\\S+', '', text)\n",
        "  tweet = re.sub(r'(\\w)\\1+', r'\\1',tweet)\n",
        "  tweet = re.sub(r'[!.?]+','',tweet)\n",
        "  return str(tweet)\n",
        "\n",
        "\n",
        "X_train_words = []\n",
        "X_eval_words = []\n",
        "\n",
        "for row in X_train:\n",
        "  X_train_words.append(pre_process(str(row)))\n",
        "\n",
        "for row in X_eval:\n",
        "  X_eval_words.append(pre_process(str(row)))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX9_7yMidBT0",
        "outputId": "611f9bc7-b1eb-49a4-86b0-77e616990379"
      },
      "source": [
        "# Building the vocabulary with the train set         (this might take a minute)\n",
        "from collections import defaultdict\n",
        "x_train = []\n",
        "\n",
        "vocab = defaultdict(lambda: 0)\n",
        "\n",
        "for idx in range(len(X_train_words)):\n",
        "    li = nltk.word_tokenize(X_train_words[idx])\n",
        "    x_train.append(li)\n",
        "\n",
        "    for word in li:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab) + 1\n",
        "print('The length of the vocabulary is: ', len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the vocabulary is:  51619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNrcBtRdfAFj"
      },
      "source": [
        "#Split eval sequence to tokens\n",
        "x_eval = []\n",
        "for idx in range(len(X_eval_words)):\n",
        "    li = nltk.word_tokenize(X_eval_words[idx])\n",
        "    x_eval.append(li)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tky_jIX5onww"
      },
      "source": [
        "# convert tokens to tensors\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "    x_train[i] = [vocab[word] for word in x_train[i]]\n",
        "\n",
        "for i in range(len(x_eval)):\n",
        "    x_eval[i] = [vocab[word] for word in x_eval[i]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzu07RGNo522",
        "outputId": "348c93d4-fb99-414b-d0b8-ee17b1918009"
      },
      "source": [
        "print('Second review:')\n",
        "print(X_train_words[1], '\\n') \n",
        "print('encoded version:')\n",
        "print(x_train[1],'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Second review:\n",
            "i checked in at 4pm even tough rom was not ready  and the staf are busy with their mobiles instead of making it fast to provide me my suite rom and in bathrom hair dryer was not kept  bathrob was not kept totaly bad experience i faced  the rates for hotel fod is 5 times more then outisde fod the rom service boys are beter then receptionist people very wel trained with quick service the receptionist people should welxome guest with smile they are seing us like we are staying for fre \n",
            "\n",
            "encoded version:\n",
            "[98, 99, 6, 87, 100, 101, 102, 71, 7, 103, 104, 4, 9, 105, 18, 106, 47, 107, 108, 109, 33, 110, 111, 112, 12, 113, 114, 115, 116, 71, 4, 6, 117, 118, 119, 7, 103, 120, 121, 7, 103, 120, 122, 123, 124, 98, 125, 9, 126, 20, 14, 127, 15, 88, 128, 86, 35, 129, 127, 9, 71, 130, 131, 18, 132, 35, 133, 134, 135, 72, 136, 47, 137, 130, 9, 133, 134, 138, 139, 140, 47, 141, 142, 18, 143, 144, 145, 146, 18, 147, 20, 148] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSZQIu_V5Rez"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMMm4hM4seOO"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation, SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Da-OkC7pQX6"
      },
      "source": [
        "# finding out max length to make all input sequences fixed\n",
        "max_len = 0\n",
        "for i in x_train:\n",
        "  if len(i)>max_len:\n",
        "    max_len = len(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDFT_KbUwszM"
      },
      "source": [
        "# padding sequences with zeros to make input length fixed\n",
        "X = sequence.pad_sequences(x_train , maxlen=max_len )  # change to max_len\n",
        "x_eval_final = sequence.pad_sequences(x_eval , maxlen=max_len )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL3iTUQAxMvl",
        "outputId": "95b573e9-c027-4918-8151-655156f552ad"
      },
      "source": [
        "# model defination\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab), embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 926, 128)          7371136   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 926, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1182      \n",
            "=================================================================\n",
            "Total params: 7,627,118\n",
            "Trainable params: 7,627,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy19ffvQy2nA",
        "outputId": "f49c690c-1490-44c8-d076-1b97accd18d6"
      },
      "source": [
        "# training model\n",
        "batch_size = 64\n",
        "model.fit(X, Y_oh_train, epochs = 10, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "547/547 - 1797s - loss: 1.1369 - accuracy: 0.4771\n",
            "Epoch 2/10\n",
            "547/547 - 1786s - loss: 0.7812 - accuracy: 0.6654\n",
            "Epoch 3/10\n",
            "547/547 - 1781s - loss: 0.6139 - accuracy: 0.7490\n",
            "Epoch 4/10\n",
            "547/547 - 1781s - loss: 0.4740 - accuracy: 0.8137\n",
            "Epoch 5/10\n",
            "547/547 - 1787s - loss: 0.3721 - accuracy: 0.8602\n",
            "Epoch 6/10\n",
            "547/547 - 1800s - loss: 0.2976 - accuracy: 0.8908\n",
            "Epoch 7/10\n",
            "547/547 - 1808s - loss: 0.2372 - accuracy: 0.9144\n",
            "Epoch 8/10\n",
            "547/547 - 1806s - loss: 0.1926 - accuracy: 0.9320\n",
            "Epoch 9/10\n",
            "547/547 - 1788s - loss: 0.1593 - accuracy: 0.9451\n",
            "Epoch 10/10\n",
            "547/547 - 1786s - loss: 0.1328 - accuracy: 0.9538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f756b9f7400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFc-KMYcAyx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777c0e89-6017-41f6-b386-a3f00ac5c106"
      },
      "source": [
        "# model saved for later reference\r\n",
        "model.save('/SOTA_Model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /SOTA_Model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnInjBgbmSna",
        "outputId": "82ff843d-0fa2-442b-b593-72ef7cf70a5b"
      },
      "source": [
        "model = models.load_model('/SOTA_Model');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utiuBJq7z2f_",
        "outputId": "3055c807-e17f-4b70-9627-c64352249224"
      },
      "source": [
        "# evaluate model with dev dataset\n",
        "score,acc = model.evaluate(x_eval_final, Y_oh_eval, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score\",score, \"Accuracy\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118/118 - 25s - loss: 0.9979 - accuracy: 0.7338\n",
            "Score 0.9979344606399536 Accuracy 0.7338311672210693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1dI5R3P5hFm"
      },
      "source": [
        "**Testing/prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_f0Gv448X9U"
      },
      "source": [
        "X_test = np.asarray(pd.read_csv('sentiment_dataset_test.csv',usecols=['review']))\n",
        "X_test = X_test.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXFL2fy890P"
      },
      "source": [
        " # convert test set - text to tokens\n",
        " x_test= []\n",
        "for row in X_test:\n",
        "  element = pre_process(str(row))\n",
        "  li = nltk.word_tokenize(element)\n",
        "  x_test.append(li)\n",
        "\n",
        "# convert tokens to index sequences\n",
        "for i in range(len(x_test)):\n",
        "    x_test[i] = [vocab[word] for word in x_test[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVe1CIJR-oYg"
      },
      "source": [
        "x_test_final = sequence.pad_sequences(x_test , maxlen=max_len )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHOKXAVm-1xF",
        "outputId": "bca2f57d-e03f-4cd9-d4cf-b8f3927b1ccf"
      },
      "source": [
        "# single prediction\r\n",
        "sentiment = model.predict(x_test_final,batch_size=1,verbose = 2)[0]\r\n",
        "y_pred = np.argmax(sentiment)\r\n",
        "print(\"Rating for first record in test set\", y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6500/6500 - 1779s\n",
            "Rating for first record in test set 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeEzaZhm_C6H",
        "outputId": "62f88204-cb7a-4cc2-d010-8ead278a8d37"
      },
      "source": [
        "# batch prediction\r\n",
        "sentiment = model.predict(x_test_final,verbose = 2)\r\n",
        "sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "204/204 - 41s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.14643435e-05, 2.43521973e-01, 6.76895499e-01, 7.79308826e-02,\n",
              "        1.42578257e-03, 2.14448330e-04],\n",
              "       [6.35145261e-05, 7.22389622e-03, 8.79305042e-03, 3.21564883e-01,\n",
              "        4.63182420e-01, 1.99172154e-01],\n",
              "       [4.22125538e-07, 9.99188006e-01, 3.89630964e-04, 3.48514615e-04,\n",
              "        5.55904844e-05, 1.77456022e-05],\n",
              "       ...,\n",
              "       [2.96230070e-07, 2.29733239e-04, 3.44768341e-04, 1.40185980e-02,\n",
              "        9.84987438e-01, 4.19133139e-04],\n",
              "       [5.50376491e-08, 1.11258414e-03, 9.83726621e-01, 1.50795560e-02,\n",
              "        7.58742390e-05, 5.30741636e-06],\n",
              "       [9.26607754e-06, 3.72438692e-02, 9.32213604e-01, 3.01857088e-02,\n",
              "        2.56482832e-04, 9.10142990e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQaW0bs1Eo3K"
      },
      "source": [
        "# extracting predicted sentiment\r\n",
        "def predictlabel(ypred):\r\n",
        "  predictedLabels = []\r\n",
        "  for i in range(len(x_test_final)):\r\n",
        "    num = np.argmax(sentiment[i])\r\n",
        "    predictedLabels.append(num)\r\n",
        "  return predictedLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHrNF48OFVCm"
      },
      "source": [
        "y_pred = predictlabel(sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eigvQT2k_Pr0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "51bb192d-85f6-4565-e004-3ed5a4c20677"
      },
      "source": [
        "data = {'review':X_test,'predicted_rating':y_pred}\r\n",
        "df_test = pd.DataFrame(data)\r\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>predicted_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Not at all what expected.   Our mountain view...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Good location as we needed to head to Reims t...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Me and my son just returned from Broadmoor Mi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The place was filthy and full of stoned backp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The hotel itself is really nice and modern wh...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  predicted_rating\n",
              "0  [Not at all what expected.   Our mountain view...                 2\n",
              "1  [Good location as we needed to head to Reims t...                 4\n",
              "2  [Me and my son just returned from Broadmoor Mi...                 1\n",
              "3  [The place was filthy and full of stoned backp...                 1\n",
              "4  [The hotel itself is really nice and modern wh...                 3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNRYwoaHFlsA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}